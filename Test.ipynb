{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import transforms, models\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from add_channel import AddChannel\n",
    "from dataset import IMDbFacialDataset, NUM_AGE_BUCKETS\n",
    "from trainer import Trainer\n",
    "\n",
    "BATCH_SIZE = 500\n",
    "DATA_LOADER_NUM_WORKERS = 5\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Using device {device}')\n",
    "\n",
    "model = torch.load('models/model.pt')\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    AddChannel(),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = IMDbFacialDataset('imdb_crop', val_transform)\n",
    "loader_test = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=DATA_LOADER_NUM_WORKERS,\n",
    "    sampler=sampler.SubsetRandomSampler(range(0, 500))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_age_range(range):\n",
    "    start = range * 5\n",
    "    return f'[{start}, {start + 4}]'\n",
    "\n",
    "model.eval()\n",
    "transform = transforms.ToPILImage()\n",
    "with torch.no_grad():\n",
    "    for x, y, f in loader_test:\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        scores = model(x)\n",
    "        _, preds = scores.max(1)\n",
    "        predicted_age = preds.cpu().numpy()[0]\n",
    "        actual_age = y.cpu().numpy()[0]\n",
    "        image = io.imread(f[0])\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "----------\n",
      "Epoch 0\n",
      "----------\n",
      "Iteration 0, training loss = 1.2735\n",
      "Val Loss: 2.3046358823776245\n",
      "Got 1205 / 4600 correct (26.195652173913043%)\n",
      "\n",
      "Iteration 100, training loss = 1.2986\n",
      "Val Loss: 2.4341587035552315\n",
      "Got 1118 / 4600 correct (24.304347826086957%)\n",
      "\n",
      "Iteration 200, training loss = 1.3743\n",
      "Val Loss: 2.428502005079518\n",
      "Got 1111 / 4600 correct (24.15217391304348%)\n",
      "\n",
      "Iteration 300, training loss = 1.2956\n",
      "Val Loss: 2.41142359505529\n",
      "Got 1146 / 4600 correct (24.913043478260867%)\n",
      "\n",
      "Iteration 400, training loss = 1.2955\n",
      "Val Loss: 2.46764702382295\n",
      "Got 1131 / 4600 correct (24.586956521739133%)\n",
      "\n",
      "Iteration 500, training loss = 1.3366\n",
      "Val Loss: 2.4378274575523706\n",
      "Got 1137 / 4600 correct (24.717391304347828%)\n",
      "\n",
      "Iteration 600, training loss = 1.3363\n",
      "Val Loss: 2.4954092450763867\n",
      "Got 1111 / 4600 correct (24.15217391304348%)\n",
      "\n",
      "Iteration 700, training loss = 1.3645\n",
      "Val Loss: 2.3933535140493643\n",
      "Got 1202 / 4600 correct (26.130434782608695%)\n",
      "\n",
      "Iteration 800, training loss = 1.2514\n",
      "Val Loss: 2.453681899153668\n",
      "Got 1172 / 4600 correct (25.47826086956522%)\n",
      "\n",
      "Iteration 900, training loss = 1.2680\n",
      "Val Loss: 2.4355491399765015\n",
      "Got 1066 / 4600 correct (23.17391304347826%)\n",
      "\n",
      "Iteration 1000, training loss = 1.4606\n",
      "Val Loss: 2.394686538240184\n",
      "Got 1170 / 4600 correct (25.43478260869565%)\n",
      "\n",
      "Iteration 1100, training loss = 1.3771\n",
      "Val Loss: 2.4203813438830166\n",
      "Got 1115 / 4600 correct (24.23913043478261%)\n",
      "\n",
      "Iteration 1200, training loss = 1.3787\n",
      "Val Loss: 2.338319664416106\n",
      "Got 1204 / 4600 correct (26.173913043478258%)\n",
      "\n",
      "Iteration 1300, training loss = 1.3571\n",
      "Val Loss: 2.364139727924181\n",
      "Got 1172 / 4600 correct (25.47826086956522%)\n",
      "\n",
      "Iteration 1400, training loss = 1.3872\n",
      "Val Loss: 2.3667860342108686\n",
      "Got 1176 / 4600 correct (25.565217391304344%)\n",
      "\n",
      "Iteration 1500, training loss = 1.3965\n",
      "Val Loss: 2.3598605135212773\n",
      "Got 1116 / 4600 correct (24.26086956521739%)\n",
      "\n",
      "Val Loss: 2.3689646306245224\n",
      "Got 1113 / 4600 correct (24.195652173913043%)\n",
      "******************************\n",
      "End of epoch 0 summary\n",
      "Total samples: 450870\n",
      "Training loss: 1.3227510796675814, accuracy: 0.5359394060372169\n",
      "Val loss: 2.3689646306245224, accuracy: 0.24195652173913043\n",
      "******************************\n",
      "----------\n",
      "Epoch 1\n",
      "----------\n",
      "Iteration 0, training loss = 1.2344\n",
      "Val Loss: 2.369591360506804\n",
      "Got 1116 / 4600 correct (24.26086956521739%)\n",
      "\n",
      "Iteration 100, training loss = 1.1658\n",
      "Val Loss: 2.498699074206145\n",
      "Got 1108 / 4600 correct (24.08695652173913%)\n",
      "\n",
      "Iteration 200, training loss = 1.1957\n",
      "Val Loss: 2.554432687552079\n",
      "Got 1171 / 4600 correct (25.456521739130434%)\n",
      "\n",
      "Iteration 300, training loss = 1.1602\n",
      "Val Loss: 2.5380699323571245\n",
      "Got 1159 / 4600 correct (25.19565217391304%)\n",
      "\n",
      "Iteration 400, training loss = 1.2144\n",
      "Val Loss: 2.4996217074601548\n",
      "Got 1242 / 4600 correct (27.0%)\n",
      "\n",
      "Iteration 500, training loss = 1.2257\n",
      "Val Loss: 2.43594039004782\n",
      "Got 1196 / 4600 correct (26.0%)\n",
      "\n",
      "Iteration 600, training loss = 1.2568\n",
      "Val Loss: 2.4929233685783716\n",
      "Got 1146 / 4600 correct (24.913043478260867%)\n",
      "\n",
      "Iteration 700, training loss = 1.2412\n",
      "Val Loss: 2.511184811592102\n",
      "Got 1116 / 4600 correct (24.26086956521739%)\n",
      "\n",
      "Iteration 800, training loss = 1.2686\n",
      "Val Loss: 2.5070797204971313\n",
      "Got 1147 / 4600 correct (24.934782608695652%)\n",
      "\n",
      "Iteration 900, training loss = 1.3882\n",
      "Val Loss: 2.47120143537936\n",
      "Got 1167 / 4600 correct (25.369565217391305%)\n",
      "\n",
      "Iteration 1000, training loss = 1.3199\n",
      "Val Loss: 2.477037295051243\n",
      "Got 1136 / 4600 correct (24.695652173913043%)\n",
      "\n",
      "Iteration 1100, training loss = 1.3060\n",
      "Val Loss: 2.5238494251085366\n",
      "Got 1167 / 4600 correct (25.369565217391305%)\n",
      "\n",
      "Iteration 1200, training loss = 1.3142\n",
      "Val Loss: 2.4376828825992085\n",
      "Got 1180 / 4600 correct (25.65217391304348%)\n",
      "\n",
      "Iteration 1300, training loss = 1.1797\n",
      "Val Loss: 2.372229762699293\n",
      "Got 1219 / 4600 correct (26.5%)\n",
      "\n",
      "Iteration 1400, training loss = 1.2856\n",
      "Val Loss: 2.4404619154722793\n",
      "Got 1197 / 4600 correct (26.021739130434785%)\n",
      "\n",
      "Iteration 1500, training loss = 1.2966\n",
      "Val Loss: 2.4426424244175786\n",
      "Got 1214 / 4600 correct (26.39130434782609%)\n",
      "\n",
      "Val Loss: 2.4484861467195596\n",
      "Got 1219 / 4600 correct (26.5%)\n",
      "******************************\n",
      "End of epoch 1 summary\n",
      "Total samples: 450870\n",
      "Training loss: 1.2685374552177664, accuracy: 0.5528245392241665\n",
      "Val loss: 2.4484861467195596, accuracy: 0.265\n",
      "******************************\n",
      "----------\n",
      "Epoch 2\n",
      "----------\n",
      "Iteration 0, training loss = 1.0722\n",
      "Val Loss: 2.448814894842065\n",
      "Got 1229 / 4600 correct (26.717391304347828%)\n",
      "\n",
      "Iteration 100, training loss = 1.1192\n",
      "Val Loss: 2.492681088654891\n",
      "Got 1200 / 4600 correct (26.08695652173913%)\n",
      "\n",
      "Iteration 200, training loss = 1.0627\n",
      "Val Loss: 2.6231030173923657\n",
      "Got 1182 / 4600 correct (25.695652173913043%)\n",
      "\n",
      "Iteration 300, training loss = 1.0631\n",
      "Val Loss: 2.599883478620778\n",
      "Got 1158 / 4600 correct (25.17391304347826%)\n",
      "\n",
      "Iteration 400, training loss = 1.1737\n",
      "Val Loss: 2.579590802607329\n",
      "Got 1145 / 4600 correct (24.891304347826086%)\n",
      "\n",
      "Iteration 500, training loss = 1.1585\n",
      "Val Loss: 2.583509491837543\n",
      "Got 1138 / 4600 correct (24.73913043478261%)\n",
      "\n",
      "Iteration 600, training loss = 1.2951\n",
      "Val Loss: 2.659897239311882\n",
      "Got 1115 / 4600 correct (24.23913043478261%)\n",
      "\n",
      "Iteration 700, training loss = 1.2198\n",
      "Val Loss: 2.541272572849108\n",
      "Got 1153 / 4600 correct (25.065217391304344%)\n",
      "\n",
      "Iteration 800, training loss = 1.2767\n",
      "Val Loss: 2.5431848246118296\n",
      "Got 1203 / 4600 correct (26.15217391304348%)\n",
      "\n",
      "Iteration 900, training loss = 1.2439\n",
      "Val Loss: 2.5353366240211157\n",
      "Got 1201 / 4600 correct (26.108695652173914%)\n",
      "\n",
      "Iteration 1000, training loss = 1.2270\n",
      "Val Loss: 2.433332728302997\n",
      "Got 1250 / 4600 correct (27.173913043478258%)\n",
      "\n",
      "Iteration 1100, training loss = 1.1716\n",
      "Val Loss: 2.5396350103875864\n",
      "Got 1141 / 4600 correct (24.804347826086957%)\n",
      "\n",
      "Iteration 1200, training loss = 1.2729\n",
      "Val Loss: 2.543213040932365\n",
      "Got 1141 / 4600 correct (24.804347826086957%)\n",
      "\n",
      "Iteration 1300, training loss = 1.3089\n",
      "Val Loss: 2.5464559897132544\n",
      "Got 1167 / 4600 correct (25.369565217391305%)\n",
      "\n",
      "Iteration 1400, training loss = 1.3382\n",
      "Val Loss: 2.469198703765869\n",
      "Got 1152 / 4600 correct (25.043478260869566%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "----------\n",
      "Epoch 0\n",
      "----------\n",
      "Iteration 0, training loss = 3.2403\n",
      "Val Loss: 2.826304264690565\n",
      "Got 578 / 4600 correct (12.565217391304348%)\n",
      "\n",
      "Iteration 100, training loss = 2.3714\n",
      "Val Loss: 2.300834666127744\n",
      "Got 855 / 4600 correct (18.586956521739133%)\n",
      "\n",
      "Iteration 200, training loss = 2.4549\n",
      "Val Loss: 2.2595231688540913\n",
      "Got 791 / 4600 correct (17.195652173913043%)\n",
      "\n",
      "Iteration 300, training loss = 2.3397\n",
      "Val Loss: 2.3188031289888467\n",
      "Got 724 / 4600 correct (15.739130434782608%)\n",
      "\n",
      "Iteration 400, training loss = 2.3961\n",
      "Val Loss: 2.2871427017709482\n",
      "Got 816 / 4600 correct (17.739130434782606%)\n",
      "\n",
      "Iteration 500, training loss = 2.4988\n",
      "Val Loss: 2.2911744947018833\n",
      "Got 1016 / 4600 correct (22.086956521739133%)\n",
      "\n",
      "Iteration 600, training loss = 2.3690\n",
      "Val Loss: 2.242384889851446\n",
      "Got 978 / 4600 correct (21.26086956521739%)\n",
      "\n",
      "Iteration 700, training loss = 2.3574\n",
      "Val Loss: 2.2710676918859067\n",
      "Got 1080 / 4600 correct (23.47826086956522%)\n",
      "\n",
      "Iteration 800, training loss = 2.4470\n",
      "Val Loss: 2.3819320875665415\n",
      "Got 593 / 4600 correct (12.891304347826088%)\n",
      "\n",
      "Iteration 900, training loss = 2.3570\n",
      "Val Loss: 2.3139936509339707\n",
      "Got 808 / 4600 correct (17.565217391304348%)\n",
      "\n",
      "Val Loss: 2.2771567261737324\n",
      "Got 933 / 4600 correct (20.282608695652176%)\n",
      "******************************\n",
      "End of epoch 0 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.396321791592749, accuracy: 0.16693060083837913\n",
      "Val loss: 2.2771567261737324, accuracy: 0.20282608695652174\n",
      "******************************\n",
      "----------\n",
      "Epoch 1\n",
      "----------\n",
      "Iteration 0, training loss = 2.3346\n",
      "Val Loss: 2.32959040351536\n",
      "Got 682 / 4600 correct (14.826086956521738%)\n",
      "\n",
      "Iteration 100, training loss = 2.4129\n",
      "Val Loss: 2.279973138933596\n",
      "Got 854 / 4600 correct (18.565217391304348%)\n",
      "\n",
      "Iteration 200, training loss = 2.3761\n",
      "Val Loss: 2.4135722699372666\n",
      "Got 745 / 4600 correct (16.195652173913043%)\n",
      "\n",
      "Iteration 300, training loss = 2.3352\n",
      "Val Loss: 2.2807498652002085\n",
      "Got 793 / 4600 correct (17.23913043478261%)\n",
      "\n",
      "Iteration 400, training loss = 2.3487\n",
      "Val Loss: 2.3306873311167178\n",
      "Got 605 / 4600 correct (13.152173913043477%)\n",
      "\n",
      "Iteration 500, training loss = 2.3396\n",
      "Val Loss: 2.32800030708313\n",
      "Got 723 / 4600 correct (15.717391304347824%)\n",
      "\n",
      "Iteration 600, training loss = 2.3435\n",
      "Val Loss: 2.2723925787469614\n",
      "Got 729 / 4600 correct (15.847826086956522%)\n",
      "\n",
      "Iteration 700, training loss = 2.3990\n",
      "Val Loss: 2.378917025483173\n",
      "Got 720 / 4600 correct (15.65217391304348%)\n",
      "\n",
      "Iteration 800, training loss = 2.3445\n",
      "Val Loss: 2.3838621429775073\n",
      "Got 798 / 4600 correct (17.347826086956523%)\n",
      "\n",
      "Iteration 900, training loss = 2.3071\n",
      "Val Loss: 2.4053103923797607\n",
      "Got 560 / 4600 correct (12.173913043478262%)\n",
      "\n",
      "Val Loss: 2.351081884425619\n",
      "Got 768 / 4600 correct (16.695652173913047%)\n",
      "******************************\n",
      "End of epoch 1 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.369516597223617, accuracy: 0.16942799476567524\n",
      "Val loss: 2.351081884425619, accuracy: 0.16695652173913045\n",
      "******************************\n",
      "----------\n",
      "Epoch 2\n",
      "----------\n",
      "Iteration 0, training loss = 2.3531\n",
      "Val Loss: 2.3198570531347524\n",
      "Got 1018 / 4600 correct (22.130434782608695%)\n",
      "\n",
      "Iteration 100, training loss = 2.3582\n",
      "Val Loss: 2.291394373644953\n",
      "Got 835 / 4600 correct (18.15217391304348%)\n",
      "\n",
      "Iteration 200, training loss = 2.4003\n",
      "Val Loss: 2.364181373430335\n",
      "Got 671 / 4600 correct (14.58695652173913%)\n",
      "\n",
      "Iteration 300, training loss = 2.2479\n",
      "Val Loss: 2.3265878376753433\n",
      "Got 652 / 4600 correct (14.173913043478262%)\n",
      "\n",
      "Iteration 400, training loss = 2.4129\n",
      "Val Loss: 2.341205633204916\n",
      "Got 715 / 4600 correct (15.543478260869565%)\n",
      "\n",
      "Iteration 500, training loss = 2.6337\n",
      "Val Loss: 2.3582856344140093\n",
      "Got 743 / 4600 correct (16.152173913043477%)\n",
      "\n",
      "Iteration 600, training loss = 2.4820\n",
      "Val Loss: 2.382922271023626\n",
      "Got 612 / 4600 correct (13.304347826086957%)\n",
      "\n",
      "Iteration 700, training loss = 2.4008\n",
      "Val Loss: 2.325936452202175\n",
      "Got 686 / 4600 correct (14.913043478260871%)\n",
      "\n",
      "Iteration 800, training loss = 2.4203\n",
      "Val Loss: 2.289830078249392\n",
      "Got 777 / 4600 correct (16.891304347826086%)\n",
      "\n",
      "Iteration 900, training loss = 2.3065\n",
      "Val Loss: 2.381973437640978\n",
      "Got 706 / 4600 correct (15.347826086956523%)\n",
      "\n",
      "Val Loss: 2.256429153939952\n",
      "Got 895 / 4600 correct (19.456521739130434%)\n",
      "******************************\n",
      "End of epoch 2 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.36841477662352, accuracy: 0.16979173597711092\n",
      "Val loss: 2.256429153939952, accuracy: 0.19456521739130433\n",
      "******************************\n",
      "----------\n",
      "Epoch 3\n",
      "----------\n",
      "Iteration 0, training loss = 2.3120\n",
      "Val Loss: 2.283911248911982\n",
      "Got 1066 / 4600 correct (23.17391304347826%)\n",
      "\n",
      "Iteration 100, training loss = 2.3734\n",
      "Val Loss: 2.4118053135664566\n",
      "Got 607 / 4600 correct (13.195652173913045%)\n",
      "\n",
      "Iteration 200, training loss = 2.3523\n",
      "Val Loss: 2.372470689856488\n",
      "Got 745 / 4600 correct (16.195652173913043%)\n",
      "\n",
      "Iteration 300, training loss = 2.3689\n",
      "Val Loss: 2.316184676211813\n",
      "Got 769 / 4600 correct (16.717391304347824%)\n",
      "\n",
      "Iteration 400, training loss = 2.2505\n",
      "Val Loss: 2.2941615529682324\n",
      "Got 773 / 4600 correct (16.804347826086957%)\n",
      "\n",
      "Iteration 500, training loss = 2.3624\n",
      "Val Loss: 2.512304534082827\n",
      "Got 641 / 4600 correct (13.934782608695654%)\n",
      "\n",
      "Iteration 600, training loss = 2.3442\n",
      "Val Loss: 2.280015447865362\n",
      "Got 771 / 4600 correct (16.76086956521739%)\n",
      "\n",
      "Iteration 700, training loss = 2.4625\n",
      "Val Loss: 2.296766592108685\n",
      "Got 748 / 4600 correct (16.26086956521739%)\n",
      "\n",
      "Iteration 800, training loss = 2.3642\n",
      "Val Loss: 2.2700985359108965\n",
      "Got 1002 / 4600 correct (21.782608695652176%)\n",
      "\n",
      "Iteration 900, training loss = 2.4563\n",
      "Val Loss: 2.294819951057434\n",
      "Got 943 / 4600 correct (20.5%)\n",
      "\n",
      "Val Loss: 2.282174017118371\n",
      "Got 708 / 4600 correct (15.391304347826088%)\n",
      "******************************\n",
      "End of epoch 3 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.367310251762263, accuracy: 0.17011777230687336\n",
      "Val loss: 2.282174017118371, accuracy: 0.15391304347826087\n",
      "******************************\n",
      "----------\n",
      "Epoch 4\n",
      "----------\n",
      "Iteration 0, training loss = 2.2533\n",
      "Val Loss: 2.367866168851438\n",
      "Got 681 / 4600 correct (14.804347826086955%)\n",
      "\n",
      "Iteration 100, training loss = 2.3492\n",
      "Val Loss: 2.2953312397003174\n",
      "Got 861 / 4600 correct (18.717391304347828%)\n",
      "\n",
      "Iteration 200, training loss = 2.3473\n",
      "Val Loss: 2.2934206620506616\n",
      "Got 1011 / 4600 correct (21.978260869565215%)\n",
      "\n",
      "Iteration 300, training loss = 2.4081\n",
      "Val Loss: 2.3005453762800796\n",
      "Got 1014 / 4600 correct (22.043478260869563%)\n",
      "\n",
      "Iteration 400, training loss = 2.2701\n",
      "Val Loss: 2.3535090166589487\n",
      "Got 651 / 4600 correct (14.152173913043478%)\n",
      "\n",
      "Iteration 500, training loss = 2.3269\n",
      "Val Loss: 2.2859435185142187\n",
      "Got 948 / 4600 correct (20.608695652173914%)\n",
      "\n",
      "Iteration 600, training loss = 2.3982\n",
      "Val Loss: 2.3070143720378047\n",
      "Got 677 / 4600 correct (14.717391304347826%)\n",
      "\n",
      "Iteration 700, training loss = 2.3645\n",
      "Val Loss: 2.288120103918988\n",
      "Got 896 / 4600 correct (19.47826086956522%)\n",
      "\n",
      "Iteration 800, training loss = 2.4818\n",
      "Val Loss: 2.2701810287392656\n",
      "Got 952 / 4600 correct (20.695652173913043%)\n",
      "\n",
      "Iteration 900, training loss = 2.3027\n",
      "Val Loss: 2.2757215344387554\n",
      "Got 1103 / 4600 correct (23.97826086956522%)\n",
      "\n",
      "Val Loss: 2.2679876037265942\n",
      "Got 990 / 4600 correct (21.521739130434785%)\n",
      "******************************\n",
      "End of epoch 4 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.369729812658113, accuracy: 0.16895113890921995\n",
      "Val loss: 2.2679876037265942, accuracy: 0.21521739130434783\n",
      "******************************\n",
      "----------\n",
      "Epoch 5\n",
      "----------\n",
      "Iteration 0, training loss = 2.2935\n",
      "Val Loss: 2.2773917602456133\n",
      "Got 741 / 4600 correct (16.108695652173914%)\n",
      "\n",
      "Iteration 100, training loss = 2.3600\n",
      "Val Loss: 2.380024951437245\n",
      "Got 633 / 4600 correct (13.76086956521739%)\n",
      "\n",
      "Iteration 200, training loss = 2.3030\n",
      "Val Loss: 2.312815407048101\n",
      "Got 660 / 4600 correct (14.347826086956522%)\n",
      "\n",
      "Iteration 300, training loss = 2.3834\n",
      "Val Loss: 2.342591591503309\n",
      "Got 1031 / 4600 correct (22.413043478260867%)\n",
      "\n",
      "Iteration 400, training loss = 2.4708\n",
      "Val Loss: 2.4014196240383647\n",
      "Got 721 / 4600 correct (15.67391304347826%)\n",
      "\n",
      "Iteration 500, training loss = 2.3570\n",
      "Val Loss: 2.3796287878699927\n",
      "Got 607 / 4600 correct (13.195652173913045%)\n",
      "\n",
      "Iteration 600, training loss = 2.3912\n",
      "Val Loss: 2.3159930809684424\n",
      "Got 897 / 4600 correct (19.5%)\n",
      "\n",
      "Iteration 700, training loss = 2.3180\n",
      "Val Loss: 2.3685266090475996\n",
      "Got 635 / 4600 correct (13.804347826086957%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 800, training loss = 2.3030\n",
      "Val Loss: 2.3201883409334267\n",
      "Got 783 / 4600 correct (17.02173913043478%)\n",
      "\n",
      "Iteration 900, training loss = 2.4141\n",
      "Val Loss: 2.291361990182296\n",
      "Got 739 / 4600 correct (16.065217391304348%)\n",
      "\n",
      "Val Loss: 2.2770765760670537\n",
      "Got 844 / 4600 correct (18.347826086956523%)\n",
      "******************************\n",
      "End of epoch 5 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.369703304739318, accuracy: 0.1692771752389824\n",
      "Val loss: 2.2770765760670537, accuracy: 0.18347826086956523\n",
      "******************************\n",
      "----------\n",
      "Epoch 6\n",
      "----------\n",
      "Iteration 0, training loss = 2.3983\n",
      "Val Loss: 2.310464268145354\n",
      "Got 732 / 4600 correct (15.91304347826087%)\n",
      "\n",
      "Iteration 100, training loss = 2.3005\n",
      "Val Loss: 2.2574506116949995\n",
      "Got 854 / 4600 correct (18.565217391304348%)\n",
      "\n",
      "Iteration 200, training loss = 2.2914\n",
      "Val Loss: 2.3264757809431655\n",
      "Got 651 / 4600 correct (14.152173913043478%)\n",
      "\n",
      "Iteration 300, training loss = 2.2698\n",
      "Val Loss: 2.238260165504787\n",
      "Got 1064 / 4600 correct (23.130434782608695%)\n",
      "\n",
      "Iteration 400, training loss = 2.2814\n",
      "Val Loss: 2.2921503315801206\n",
      "Got 1040 / 4600 correct (22.608695652173914%)\n",
      "\n",
      "Iteration 500, training loss = 2.3279\n",
      "Val Loss: 2.3283793304277505\n",
      "Got 596 / 4600 correct (12.956521739130435%)\n",
      "\n",
      "Iteration 600, training loss = 2.4020\n",
      "Val Loss: 2.3737208428590195\n",
      "Got 759 / 4600 correct (16.5%)\n",
      "\n",
      "Iteration 700, training loss = 2.3731\n",
      "Val Loss: 2.324085727981899\n",
      "Got 648 / 4600 correct (14.08695652173913%)\n",
      "\n",
      "Iteration 800, training loss = 2.3379\n",
      "Val Loss: 2.276009818781977\n",
      "Got 1071 / 4600 correct (23.282608695652172%)\n",
      "\n",
      "Iteration 900, training loss = 2.3821\n",
      "Val Loss: 2.326635345168736\n",
      "Got 758 / 4600 correct (16.47826086956522%)\n",
      "\n",
      "Val Loss: 2.320581835249196\n",
      "Got 921 / 4600 correct (20.02173913043478%)\n",
      "******************************\n",
      "End of epoch 6 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.36771820396721, accuracy: 0.1706301151107858\n",
      "Val loss: 2.320581835249196, accuracy: 0.20021739130434782\n",
      "******************************\n",
      "----------\n",
      "Epoch 7\n",
      "----------\n",
      "Iteration 0, training loss = 2.3544\n",
      "Val Loss: 2.2546584813491157\n",
      "Got 1113 / 4600 correct (24.195652173913043%)\n",
      "\n",
      "Iteration 100, training loss = 2.3078\n",
      "Val Loss: 2.2914081604584404\n",
      "Got 789 / 4600 correct (17.152173913043477%)\n",
      "\n",
      "Iteration 200, training loss = 2.4111\n",
      "Val Loss: 2.3812960749087124\n",
      "Got 921 / 4600 correct (20.02173913043478%)\n",
      "\n",
      "Iteration 300, training loss = 2.4065\n",
      "Val Loss: 2.349846150564111\n",
      "Got 821 / 4600 correct (17.847826086956523%)\n",
      "\n",
      "Iteration 400, training loss = 2.3482\n",
      "Val Loss: 2.2575967881990517\n",
      "Got 904 / 4600 correct (19.652173913043477%)\n",
      "\n",
      "Iteration 500, training loss = 2.4078\n",
      "Val Loss: 2.2948809810306714\n",
      "Got 858 / 4600 correct (18.65217391304348%)\n",
      "\n",
      "Iteration 600, training loss = 2.3937\n",
      "Val Loss: 2.290029562037924\n",
      "Got 1058 / 4600 correct (23.0%)\n",
      "\n",
      "Iteration 700, training loss = 2.3381\n",
      "Val Loss: 2.382989727932474\n",
      "Got 625 / 4600 correct (13.586956521739129%)\n",
      "\n",
      "Iteration 800, training loss = 2.3933\n",
      "Val Loss: 2.311688158823096\n",
      "Got 694 / 4600 correct (15.08695652173913%)\n",
      "\n",
      "Iteration 900, training loss = 2.3586\n",
      "Val Loss: 2.2909334172373232\n",
      "Got 937 / 4600 correct (20.369565217391305%)\n",
      "\n",
      "Val Loss: 2.3068291829979937\n",
      "Got 704 / 4600 correct (15.304347826086955%)\n",
      "******************************\n",
      "End of epoch 7 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.3644374546410436, accuracy: 0.17079646017699113\n",
      "Val loss: 2.3068291829979937, accuracy: 0.15304347826086956\n",
      "******************************\n",
      "----------\n",
      "Epoch 8\n",
      "----------\n",
      "Iteration 0, training loss = 2.3431\n",
      "Val Loss: 2.3119704101396645\n",
      "Got 712 / 4600 correct (15.478260869565217%)\n",
      "\n",
      "Iteration 100, training loss = 2.4321\n",
      "Val Loss: 2.3127957219662876\n",
      "Got 908 / 4600 correct (19.73913043478261%)\n",
      "\n",
      "Iteration 200, training loss = 2.3807\n",
      "Val Loss: 2.330213484556779\n",
      "Got 924 / 4600 correct (20.08695652173913%)\n",
      "\n",
      "Iteration 300, training loss = 2.4277\n",
      "Val Loss: 2.428030050319174\n",
      "Got 633 / 4600 correct (13.76086956521739%)\n",
      "\n",
      "Iteration 400, training loss = 2.2587\n",
      "Val Loss: 2.3359519606051236\n",
      "Got 623 / 4600 correct (13.543478260869565%)\n",
      "\n",
      "Iteration 500, training loss = 2.2500\n",
      "Val Loss: 2.2926584896834\n",
      "Got 875 / 4600 correct (19.021739130434785%)\n",
      "\n",
      "Iteration 600, training loss = 2.4825\n",
      "Val Loss: 2.280649060788362\n",
      "Got 909 / 4600 correct (19.760869565217394%)\n",
      "\n",
      "Iteration 700, training loss = 2.4117\n",
      "Val Loss: 2.4774202782174815\n",
      "Got 626 / 4600 correct (13.608695652173914%)\n",
      "\n",
      "Iteration 800, training loss = 2.3687\n",
      "Val Loss: 2.296789656514707\n",
      "Got 1109 / 4600 correct (24.108695652173914%)\n",
      "\n",
      "Iteration 900, training loss = 2.4293\n",
      "Val Loss: 2.344028027161308\n",
      "Got 710 / 4600 correct (15.434782608695652%)\n",
      "\n",
      "Val Loss: 2.326735221821329\n",
      "Got 782 / 4600 correct (17.0%)\n",
      "******************************\n",
      "End of epoch 8 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.3696495258956465, accuracy: 0.1700845032936323\n",
      "Val loss: 2.326735221821329, accuracy: 0.17\n",
      "******************************\n",
      "----------\n",
      "Epoch 9\n",
      "----------\n",
      "Iteration 0, training loss = 2.3925\n",
      "Val Loss: 2.313287719436314\n",
      "Got 829 / 4600 correct (18.02173913043478%)\n",
      "\n",
      "Iteration 100, training loss = 2.3137\n",
      "Val Loss: 2.247326830159063\n",
      "Got 802 / 4600 correct (17.434782608695652%)\n",
      "\n",
      "Iteration 200, training loss = 2.2237\n",
      "Val Loss: 2.24074459594229\n",
      "Got 716 / 4600 correct (15.565217391304348%)\n",
      "\n",
      "Iteration 300, training loss = 2.2216\n",
      "Val Loss: 2.2198458650837773\n",
      "Got 972 / 4600 correct (21.130434782608695%)\n",
      "\n",
      "Iteration 400, training loss = 2.2149\n",
      "Val Loss: 2.2307199861692344\n",
      "Got 812 / 4600 correct (17.652173913043477%)\n",
      "\n",
      "Iteration 500, training loss = 2.2785\n",
      "Val Loss: 2.2296832229780112\n",
      "Got 829 / 4600 correct (18.02173913043478%)\n",
      "\n",
      "Iteration 600, training loss = 2.2669\n",
      "Val Loss: 2.2193647571232007\n",
      "Got 936 / 4600 correct (20.347826086956523%)\n",
      "\n",
      "Iteration 700, training loss = 2.2688\n",
      "Val Loss: 2.237602192422618\n",
      "Got 760 / 4600 correct (16.52173913043478%)\n",
      "\n",
      "Iteration 800, training loss = 2.2792\n",
      "Val Loss: 2.2350407527840654\n",
      "Got 707 / 4600 correct (15.369565217391305%)\n",
      "\n",
      "Iteration 900, training loss = 2.2945\n",
      "Val Loss: 2.226103601248368\n",
      "Got 790 / 4600 correct (17.17391304347826%)\n",
      "\n",
      "Val Loss: 2.2300232648849487\n",
      "Got 781 / 4600 correct (16.97826086956522%)\n",
      "******************************\n",
      "End of epoch 9 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.2554470611791992, accuracy: 0.1897110031716459\n",
      "Val loss: 2.2300232648849487, accuracy: 0.16978260869565218\n",
      "******************************\n",
      "----------\n",
      "Epoch 10\n",
      "----------\n",
      "Iteration 0, training loss = 2.1626\n",
      "Val Loss: 2.2345930804377017\n",
      "Got 774 / 4600 correct (16.82608695652174%)\n",
      "\n",
      "Iteration 100, training loss = 2.2341\n",
      "Val Loss: 2.2496923571047573\n",
      "Got 690 / 4600 correct (15.0%)\n",
      "\n",
      "Iteration 200, training loss = 2.2932\n",
      "Val Loss: 2.2118688407151597\n",
      "Got 914 / 4600 correct (19.869565217391305%)\n",
      "\n",
      "Iteration 300, training loss = 2.2682\n",
      "Val Loss: 2.2016300014827563\n",
      "Got 1010 / 4600 correct (21.956521739130437%)\n",
      "\n",
      "Iteration 400, training loss = 2.2283\n",
      "Val Loss: 2.2211224773655767\n",
      "Got 827 / 4600 correct (17.97826086956522%)\n",
      "\n",
      "Iteration 500, training loss = 2.3153\n",
      "Val Loss: 2.2193728218907895\n",
      "Got 971 / 4600 correct (21.108695652173914%)\n",
      "\n",
      "Iteration 600, training loss = 2.2527\n",
      "Val Loss: 2.2351710485375444\n",
      "Got 757 / 4600 correct (16.456521739130434%)\n",
      "\n",
      "Iteration 700, training loss = 2.1754\n",
      "Val Loss: 2.2079919732135274\n",
      "Got 814 / 4600 correct (17.695652173913043%)\n",
      "\n",
      "Iteration 800, training loss = 2.1772\n",
      "Val Loss: 2.224254970965178\n",
      "Got 951 / 4600 correct (20.67391304347826%)\n",
      "\n",
      "Iteration 900, training loss = 2.2739\n",
      "Val Loss: 2.21870916304381\n",
      "Got 868 / 4600 correct (18.869565217391305%)\n",
      "\n",
      "Val Loss: 2.216299761896548\n",
      "Got 875 / 4600 correct (19.021739130434785%)\n",
      "******************************\n",
      "End of epoch 10 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.2527980227631894, accuracy: 0.18910994299909065\n",
      "Val loss: 2.216299761896548, accuracy: 0.19021739130434784\n",
      "******************************\n",
      "----------\n",
      "Epoch 11\n",
      "----------\n",
      "Iteration 0, training loss = 2.2206\n",
      "Val Loss: 2.2118034466453222\n",
      "Got 909 / 4600 correct (19.760869565217394%)\n",
      "\n",
      "Iteration 100, training loss = 2.2591\n",
      "Val Loss: 2.220470164133155\n",
      "Got 699 / 4600 correct (15.195652173913043%)\n",
      "\n",
      "Iteration 200, training loss = 2.2759\n",
      "Val Loss: 2.233349929685178\n",
      "Got 851 / 4600 correct (18.5%)\n",
      "\n",
      "Iteration 300, training loss = 2.3037\n",
      "Val Loss: 2.2199485664782315\n",
      "Got 878 / 4600 correct (19.086956521739133%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 400, training loss = 2.2653\n",
      "Val Loss: 2.214890101681585\n",
      "Got 847 / 4600 correct (18.413043478260867%)\n",
      "\n",
      "Iteration 500, training loss = 2.2002\n",
      "Val Loss: 2.225829565006754\n",
      "Got 945 / 4600 correct (20.543478260869566%)\n",
      "\n",
      "Iteration 600, training loss = 2.2368\n",
      "Val Loss: 2.230644651081251\n",
      "Got 774 / 4600 correct (16.82608695652174%)\n",
      "\n",
      "Iteration 700, training loss = 2.2790\n",
      "Val Loss: 2.2298211636750596\n",
      "Got 774 / 4600 correct (16.82608695652174%)\n",
      "\n",
      "Iteration 800, training loss = 2.2325\n",
      "Val Loss: 2.2222246812737505\n",
      "Got 845 / 4600 correct (18.369565217391305%)\n",
      "\n",
      "Iteration 900, training loss = 2.2770\n",
      "Val Loss: 2.2307366910188096\n",
      "Got 883 / 4600 correct (19.195652173913043%)\n",
      "\n",
      "Val Loss: 2.231595189675041\n",
      "Got 907 / 4600 correct (19.717391304347824%)\n",
      "******************************\n",
      "End of epoch 11 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.252544464035858, accuracy: 0.18916095548606027\n",
      "Val loss: 2.231595189675041, accuracy: 0.19717391304347825\n",
      "******************************\n",
      "----------\n",
      "Epoch 12\n",
      "----------\n",
      "Iteration 0, training loss = 2.2307\n",
      "Val Loss: 2.2291539026343306\n",
      "Got 920 / 4600 correct (20.0%)\n",
      "\n",
      "Iteration 100, training loss = 2.2389\n",
      "Val Loss: 2.2426344311755635\n",
      "Got 756 / 4600 correct (16.434782608695652%)\n",
      "\n",
      "Iteration 200, training loss = 2.2298\n",
      "Val Loss: 2.2296533895575483\n",
      "Got 726 / 4600 correct (15.782608695652172%)\n",
      "\n",
      "Iteration 300, training loss = 2.2136\n",
      "Val Loss: 2.215023916700612\n",
      "Got 949 / 4600 correct (20.630434782608695%)\n",
      "\n",
      "Iteration 400, training loss = 2.2144\n",
      "Val Loss: 2.2212981089301733\n",
      "Got 819 / 4600 correct (17.804347826086957%)\n",
      "\n",
      "Iteration 500, training loss = 2.2765\n",
      "Val Loss: 2.2301312581352564\n",
      "Got 736 / 4600 correct (16.0%)\n",
      "\n",
      "Iteration 600, training loss = 2.2210\n",
      "Val Loss: 2.216911186342654\n",
      "Got 719 / 4600 correct (15.630434782608695%)\n",
      "\n",
      "Iteration 700, training loss = 2.2621\n",
      "Val Loss: 2.2080283994260044\n",
      "Got 1033 / 4600 correct (22.456521739130437%)\n",
      "\n",
      "Iteration 800, training loss = 2.2229\n",
      "Val Loss: 2.244212674058002\n",
      "Got 854 / 4600 correct (18.565217391304348%)\n",
      "\n",
      "Iteration 900, training loss = 2.2303\n",
      "Val Loss: 2.225999142812646\n",
      "Got 767 / 4600 correct (16.67391304347826%)\n",
      "\n",
      "Val Loss: 2.2347268073455147\n",
      "Got 704 / 4600 correct (15.304347826086955%)\n",
      "******************************\n",
      "End of epoch 12 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.254057767389248, accuracy: 0.18830483287865682\n",
      "Val loss: 2.2347268073455147, accuracy: 0.15304347826086956\n",
      "******************************\n",
      "----------\n",
      "Epoch 13\n",
      "----------\n",
      "Iteration 0, training loss = 2.1895\n",
      "Val Loss: 2.238024649412736\n",
      "Got 688 / 4600 correct (14.956521739130435%)\n",
      "\n",
      "Iteration 100, training loss = 2.2484\n",
      "Val Loss: 2.2188663845476895\n",
      "Got 803 / 4600 correct (17.456521739130434%)\n",
      "\n",
      "Iteration 200, training loss = 2.2686\n",
      "Val Loss: 2.2077837353167324\n",
      "Got 871 / 4600 correct (18.934782608695652%)\n",
      "\n",
      "Iteration 300, training loss = 2.2383\n",
      "Val Loss: 2.225234010945196\n",
      "Got 914 / 4600 correct (19.869565217391305%)\n",
      "\n",
      "Iteration 400, training loss = 2.2117\n",
      "Val Loss: 2.230142406795336\n",
      "Got 944 / 4600 correct (20.52173913043478%)\n",
      "\n",
      "Iteration 500, training loss = 2.2576\n",
      "Val Loss: 2.218702259271041\n",
      "Got 875 / 4600 correct (19.021739130434785%)\n",
      "\n",
      "Iteration 600, training loss = 2.2553\n",
      "Val Loss: 2.2394988536834717\n",
      "Got 733 / 4600 correct (15.934782608695652%)\n",
      "\n",
      "Iteration 700, training loss = 2.2162\n",
      "Val Loss: 2.209802378778872\n",
      "Got 917 / 4600 correct (19.934782608695652%)\n",
      "\n",
      "Iteration 800, training loss = 2.2519\n",
      "Val Loss: 2.226645962051723\n",
      "Got 774 / 4600 correct (16.82608695652174%)\n",
      "\n",
      "Iteration 900, training loss = 2.2338\n",
      "Val Loss: 2.2133459474729453\n",
      "Got 952 / 4600 correct (20.695652173913043%)\n",
      "\n",
      "Val Loss: 2.212749289429706\n",
      "Got 957 / 4600 correct (20.804347826086953%)\n",
      "******************************\n",
      "End of epoch 13 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.2538281792924058, accuracy: 0.18858429258988177\n",
      "Val loss: 2.212749289429706, accuracy: 0.20804347826086955\n",
      "******************************\n",
      "----------\n",
      "Epoch 14\n",
      "----------\n",
      "Iteration 0, training loss = 2.2540\n",
      "Val Loss: 2.2153841153435083\n",
      "Got 908 / 4600 correct (19.73913043478261%)\n",
      "\n",
      "Iteration 100, training loss = 2.2334\n",
      "Val Loss: 2.2386257441147515\n",
      "Got 743 / 4600 correct (16.152173913043477%)\n",
      "\n",
      "Iteration 200, training loss = 2.3117\n",
      "Val Loss: 2.2506561020146245\n",
      "Got 725 / 4600 correct (15.760869565217392%)\n",
      "\n",
      "Iteration 300, training loss = 2.2907\n",
      "Val Loss: 2.255039686742036\n",
      "Got 734 / 4600 correct (15.956521739130435%)\n",
      "\n",
      "Iteration 400, training loss = 2.2406\n",
      "Val Loss: 2.2139651775360107\n",
      "Got 974 / 4600 correct (21.173913043478258%)\n",
      "\n",
      "Iteration 500, training loss = 2.2760\n",
      "Val Loss: 2.231990897137186\n",
      "Got 835 / 4600 correct (18.15217391304348%)\n",
      "\n",
      "Iteration 600, training loss = 2.1967\n",
      "Val Loss: 2.2197533897731616\n",
      "Got 736 / 4600 correct (16.0%)\n",
      "\n",
      "Iteration 700, training loss = 2.2652\n",
      "Val Loss: 2.2457976393077685\n",
      "Got 698 / 4600 correct (15.17391304347826%)\n",
      "\n",
      "Iteration 800, training loss = 2.2209\n",
      "Val Loss: 2.2119950004245923\n",
      "Got 1010 / 4600 correct (21.956521739130437%)\n",
      "\n",
      "Iteration 900, training loss = 2.2408\n",
      "Val Loss: 2.239791450293168\n",
      "Got 683 / 4600 correct (14.847826086956523%)\n",
      "\n",
      "Val Loss: 2.228391066841457\n",
      "Got 687 / 4600 correct (14.934782608695652%)\n",
      "******************************\n",
      "End of epoch 14 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.254034505436266, accuracy: 0.18926076252578347\n",
      "Val loss: 2.228391066841457, accuracy: 0.14934782608695651\n",
      "******************************\n",
      "----------\n",
      "Epoch 15\n",
      "----------\n",
      "Iteration 0, training loss = 2.2131\n",
      "Val Loss: 2.217310413070347\n",
      "Got 812 / 4600 correct (17.652173913043477%)\n",
      "\n",
      "Iteration 100, training loss = 2.2670\n",
      "Val Loss: 2.2132253698680713\n",
      "Got 876 / 4600 correct (19.043478260869566%)\n",
      "\n",
      "Iteration 200, training loss = 2.2229\n",
      "Val Loss: 2.2386149582655532\n",
      "Got 683 / 4600 correct (14.847826086956523%)\n",
      "\n",
      "Iteration 300, training loss = 2.2223\n",
      "Val Loss: 2.220312289569689\n",
      "Got 879 / 4600 correct (19.108695652173914%)\n",
      "\n",
      "Iteration 400, training loss = 2.3125\n",
      "Val Loss: 2.2245220205058223\n",
      "Got 849 / 4600 correct (18.456521739130434%)\n",
      "\n",
      "Iteration 500, training loss = 2.2245\n",
      "Val Loss: 2.236608448235885\n",
      "Got 701 / 4600 correct (15.239130434782608%)\n",
      "\n",
      "Iteration 600, training loss = 2.2290\n",
      "Val Loss: 2.225923455279806\n",
      "Got 973 / 4600 correct (21.15217391304348%)\n",
      "\n",
      "Iteration 700, training loss = 2.2466\n",
      "Val Loss: 2.223652518313864\n",
      "Got 855 / 4600 correct (18.586956521739133%)\n",
      "\n",
      "Iteration 800, training loss = 2.2054\n",
      "Val Loss: 2.2099708059559697\n",
      "Got 848 / 4600 correct (18.434782608695652%)\n",
      "\n",
      "Iteration 900, training loss = 2.2078\n",
      "Val Loss: 2.226354241371155\n",
      "Got 902 / 4600 correct (19.608695652173914%)\n",
      "\n",
      "Val Loss: 2.2230233265006025\n",
      "Got 926 / 4600 correct (20.130434782608695%)\n",
      "******************************\n",
      "End of epoch 15 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.254033372653211, accuracy: 0.1882893073391443\n",
      "Val loss: 2.2230233265006025, accuracy: 0.20130434782608694\n",
      "******************************\n",
      "----------\n",
      "Epoch 16\n",
      "----------\n",
      "Iteration 0, training loss = 2.2516\n",
      "Val Loss: 2.22235571819803\n",
      "Got 917 / 4600 correct (19.934782608695652%)\n",
      "\n",
      "Iteration 100, training loss = 2.2801\n",
      "Val Loss: 2.2367056297219317\n",
      "Got 730 / 4600 correct (15.869565217391305%)\n",
      "\n",
      "Iteration 200, training loss = 2.1923\n",
      "Val Loss: 2.2364789040192314\n",
      "Got 717 / 4600 correct (15.58695652173913%)\n",
      "\n",
      "Iteration 300, training loss = 2.2330\n",
      "Val Loss: 2.2142801388450293\n",
      "Got 816 / 4600 correct (17.739130434782606%)\n",
      "\n",
      "Iteration 400, training loss = 2.3009\n",
      "Val Loss: 2.222147283346757\n",
      "Got 720 / 4600 correct (15.65217391304348%)\n",
      "\n",
      "Iteration 500, training loss = 2.2645\n",
      "Val Loss: 2.23294530744138\n",
      "Got 794 / 4600 correct (17.26086956521739%)\n",
      "\n",
      "Iteration 600, training loss = 2.2793\n",
      "Val Loss: 2.2240486248679785\n",
      "Got 854 / 4600 correct (18.565217391304348%)\n",
      "\n",
      "Iteration 700, training loss = 2.2087\n",
      "Val Loss: 2.22985825849616\n",
      "Got 772 / 4600 correct (16.782608695652172%)\n",
      "\n",
      "Iteration 800, training loss = 2.2841\n",
      "Val Loss: 2.2295337345289146\n",
      "Got 720 / 4600 correct (15.65217391304348%)\n",
      "\n",
      "Iteration 900, training loss = 2.2383\n",
      "Val Loss: 2.2015487940415093\n",
      "Got 1021 / 4600 correct (22.195652173913043%)\n",
      "\n",
      "Val Loss: 2.2060284148091855\n",
      "Got 997 / 4600 correct (21.67391304347826%)\n",
      "******************************\n",
      "End of epoch 16 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.2541975586741185, accuracy: 0.18769933683766937\n",
      "Val loss: 2.2060284148091855, accuracy: 0.2167391304347826\n",
      "******************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 17\n",
      "----------\n",
      "Iteration 0, training loss = 2.2638\n",
      "Val Loss: 2.213887131732443\n",
      "Got 915 / 4600 correct (19.891304347826086%)\n",
      "\n",
      "Iteration 100, training loss = 2.2258\n",
      "Val Loss: 2.2060803537783413\n",
      "Got 886 / 4600 correct (19.26086956521739%)\n",
      "\n",
      "Iteration 200, training loss = 2.2394\n",
      "Val Loss: 2.217172990674558\n",
      "Got 920 / 4600 correct (20.0%)\n",
      "\n",
      "Iteration 300, training loss = 2.2512\n",
      "Val Loss: 2.227327497109123\n",
      "Got 909 / 4600 correct (19.760869565217394%)\n",
      "\n",
      "Iteration 400, training loss = 2.2596\n",
      "Val Loss: 2.220905573471733\n",
      "Got 769 / 4600 correct (16.717391304347824%)\n",
      "\n",
      "Iteration 500, training loss = 2.2899\n",
      "Val Loss: 2.2177438995112544\n",
      "Got 1025 / 4600 correct (22.282608695652172%)\n",
      "\n",
      "Iteration 600, training loss = 2.2485\n",
      "Val Loss: 2.222827786984651\n",
      "Got 728 / 4600 correct (15.82608695652174%)\n",
      "\n",
      "Iteration 700, training loss = 2.2955\n",
      "Val Loss: 2.2363298716752427\n",
      "Got 701 / 4600 correct (15.239130434782608%)\n",
      "\n",
      "Iteration 800, training loss = 2.2415\n",
      "Val Loss: 2.23088640752046\n",
      "Got 763 / 4600 correct (16.58695652173913%)\n",
      "\n",
      "Iteration 900, training loss = 2.3091\n",
      "Val Loss: 2.2352210594260176\n",
      "Got 804 / 4600 correct (17.47826086956522%)\n",
      "\n",
      "Val Loss: 2.237396302430526\n",
      "Got 803 / 4600 correct (17.456521739130434%)\n",
      "******************************\n",
      "End of epoch 17 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.2531141350231088, accuracy: 0.18861090780047463\n",
      "Val loss: 2.237396302430526, accuracy: 0.17456521739130434\n",
      "******************************\n",
      "----------\n",
      "Epoch 18\n",
      "----------\n",
      "Iteration 0, training loss = 2.2449\n",
      "Val Loss: 2.2314512729644775\n",
      "Got 831 / 4600 correct (18.065217391304348%)\n",
      "\n",
      "Iteration 100, training loss = 2.1885\n",
      "Val Loss: 2.2157652740893155\n",
      "Got 759 / 4600 correct (16.5%)\n",
      "\n",
      "Iteration 200, training loss = 2.2652\n",
      "Val Loss: 2.2228854842807935\n",
      "Got 764 / 4600 correct (16.608695652173914%)\n",
      "\n",
      "Iteration 300, training loss = 2.3049\n",
      "Val Loss: 2.251842799394027\n",
      "Got 683 / 4600 correct (14.847826086956523%)\n",
      "\n",
      "Iteration 400, training loss = 2.2355\n",
      "Val Loss: 2.234258693197499\n",
      "Got 761 / 4600 correct (16.543478260869566%)\n",
      "\n",
      "Iteration 500, training loss = 2.2768\n",
      "Val Loss: 2.214892978253572\n",
      "Got 1052 / 4600 correct (22.869565217391305%)\n",
      "\n",
      "Iteration 600, training loss = 2.2227\n",
      "Val Loss: 2.219221918479256\n",
      "Got 683 / 4600 correct (14.847826086956523%)\n",
      "\n",
      "Iteration 700, training loss = 2.2763\n",
      "Val Loss: 2.2424651177033135\n",
      "Got 804 / 4600 correct (17.47826086956522%)\n",
      "\n",
      "Iteration 800, training loss = 2.2831\n",
      "Val Loss: 2.2352683285008306\n",
      "Got 717 / 4600 correct (15.58695652173913%)\n",
      "\n",
      "Iteration 900, training loss = 2.2589\n",
      "Val Loss: 2.226006404213283\n",
      "Got 697 / 4600 correct (15.152173913043478%)\n",
      "\n",
      "Val Loss: 2.23186283007912\n",
      "Got 689 / 4600 correct (14.978260869565219%)\n",
      "******************************\n",
      "End of epoch 18 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.2540314320961437, accuracy: 0.18805420631224076\n",
      "Val loss: 2.23186283007912, accuracy: 0.1497826086956522\n",
      "******************************\n",
      "----------\n",
      "Epoch 19\n",
      "----------\n",
      "Iteration 0, training loss = 2.2739\n",
      "Val Loss: 2.227929840917173\n",
      "Got 738 / 4600 correct (16.043478260869566%)\n",
      "\n",
      "Iteration 100, training loss = 2.3406\n",
      "Val Loss: 2.2403800021047178\n",
      "Got 682 / 4600 correct (14.826086956521738%)\n",
      "\n",
      "Iteration 200, training loss = 2.1801\n",
      "Val Loss: 2.2635332294132398\n",
      "Got 691 / 4600 correct (15.021739130434783%)\n",
      "\n",
      "Iteration 300, training loss = 2.2648\n",
      "Val Loss: 2.231272324271824\n",
      "Got 780 / 4600 correct (16.956521739130434%)\n",
      "\n",
      "Iteration 400, training loss = 2.2323\n",
      "Val Loss: 2.211847134258436\n",
      "Got 976 / 4600 correct (21.217391304347828%)\n",
      "\n",
      "Iteration 500, training loss = 2.2793\n",
      "Val Loss: 2.2338788820349653\n",
      "Got 758 / 4600 correct (16.47826086956522%)\n",
      "\n",
      "Iteration 600, training loss = 2.2135\n",
      "Val Loss: 2.2273468608441562\n",
      "Got 763 / 4600 correct (16.58695652173913%)\n",
      "\n",
      "Iteration 700, training loss = 2.2053\n",
      "Val Loss: 2.2144071900326274\n",
      "Got 812 / 4600 correct (17.652173913043477%)\n",
      "\n",
      "Iteration 800, training loss = 2.2417\n",
      "Val Loss: 2.2342206291530444\n",
      "Got 859 / 4600 correct (18.67391304347826%)\n",
      "\n",
      "Iteration 900, training loss = 2.2584\n",
      "Val Loss: 2.212800471679024\n",
      "Got 890 / 4600 correct (19.34782608695652%)\n",
      "\n",
      "Val Loss: 2.2108362032019575\n",
      "Got 909 / 4600 correct (19.760869565217394%)\n",
      "******************************\n",
      "End of epoch 19 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.2534097915379263, accuracy: 0.1877836183378801\n",
      "Val loss: 2.2108362032019575, accuracy: 0.19760869565217393\n",
      "******************************\n",
      "----------\n",
      "Epoch 20\n",
      "----------\n",
      "Iteration 0, training loss = 2.1967\n",
      "Val Loss: 2.2165818162586377\n",
      "Got 869 / 4600 correct (18.891304347826086%)\n",
      "\n",
      "Iteration 100, training loss = 2.2783\n",
      "Val Loss: 2.2428442706232485\n",
      "Got 734 / 4600 correct (15.956521739130435%)\n",
      "\n",
      "Iteration 200, training loss = 2.3512\n",
      "Val Loss: 2.2148217973501785\n",
      "Got 870 / 4600 correct (18.913043478260867%)\n",
      "\n",
      "Iteration 300, training loss = 2.2683\n",
      "Val Loss: 2.230653633242068\n",
      "Got 864 / 4600 correct (18.782608695652172%)\n",
      "\n",
      "Iteration 400, training loss = 2.2520\n",
      "Val Loss: 2.2314238392788432\n",
      "Got 658 / 4600 correct (14.304347826086957%)\n",
      "\n",
      "Iteration 500, training loss = 2.2364\n",
      "Val Loss: 2.231876077859298\n",
      "Got 707 / 4600 correct (15.369565217391305%)\n",
      "\n",
      "Iteration 600, training loss = 2.2334\n",
      "Val Loss: 2.2242073287134585\n",
      "Got 815 / 4600 correct (17.717391304347828%)\n",
      "\n",
      "Iteration 700, training loss = 2.2435\n",
      "Val Loss: 2.205023065857265\n",
      "Got 1079 / 4600 correct (23.456521739130434%)\n",
      "\n",
      "Iteration 800, training loss = 2.2562\n",
      "Val Loss: 2.2093158493871274\n",
      "Got 1035 / 4600 correct (22.5%)\n",
      "\n",
      "Iteration 900, training loss = 2.2248\n",
      "Val Loss: 2.238621120867522\n",
      "Got 738 / 4600 correct (16.043478260869566%)\n",
      "\n",
      "Val Loss: 2.233495997345966\n",
      "Got 772 / 4600 correct (16.782608695652172%)\n",
      "******************************\n",
      "End of epoch 20 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.254289784683059, accuracy: 0.18722248098121408\n",
      "Val loss: 2.233495997345966, accuracy: 0.16782608695652174\n",
      "******************************\n",
      "----------\n",
      "Epoch 21\n",
      "----------\n",
      "Iteration 0, training loss = 2.2399\n",
      "Val Loss: 2.227101979048356\n",
      "Got 733 / 4600 correct (15.934782608695652%)\n",
      "\n",
      "Iteration 100, training loss = 2.2932\n",
      "Val Loss: 2.216032520584438\n",
      "Got 898 / 4600 correct (19.52173913043478%)\n",
      "\n",
      "Iteration 200, training loss = 2.2892\n",
      "Val Loss: 2.222858745118846\n",
      "Got 787 / 4600 correct (17.108695652173914%)\n",
      "\n",
      "Iteration 300, training loss = 2.2634\n",
      "Val Loss: 2.221688477889351\n",
      "Got 706 / 4600 correct (15.347826086956523%)\n",
      "\n",
      "Iteration 400, training loss = 2.2679\n",
      "Val Loss: 2.223524031431779\n",
      "Got 762 / 4600 correct (16.565217391304348%)\n",
      "\n",
      "Iteration 500, training loss = 2.2647\n",
      "Val Loss: 2.240875420363053\n",
      "Got 748 / 4600 correct (16.26086956521739%)\n",
      "\n",
      "Iteration 600, training loss = 2.2306\n",
      "Val Loss: 2.233783835950105\n",
      "Got 736 / 4600 correct (16.0%)\n",
      "\n",
      "Iteration 700, training loss = 2.3326\n",
      "Val Loss: 2.215134330417799\n",
      "Got 908 / 4600 correct (19.73913043478261%)\n",
      "\n",
      "Iteration 800, training loss = 2.2274\n",
      "Val Loss: 2.258595813875613\n",
      "Got 693 / 4600 correct (15.065217391304348%)\n",
      "\n",
      "Iteration 900, training loss = 2.1636\n",
      "Val Loss: 2.2178578065789263\n",
      "Got 830 / 4600 correct (18.043478260869566%)\n",
      "\n",
      "Val Loss: 2.2171407886173413\n",
      "Got 873 / 4600 correct (18.978260869565215%)\n",
      "******************************\n",
      "End of epoch 21 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.254020678649885, accuracy: 0.1881895002994211\n",
      "Val loss: 2.2171407886173413, accuracy: 0.18978260869565217\n",
      "******************************\n",
      "----------\n",
      "Epoch 22\n",
      "----------\n",
      "Iteration 0, training loss = 2.2595\n",
      "Val Loss: 2.2153654616812\n",
      "Got 918 / 4600 correct (19.956521739130434%)\n",
      "\n",
      "Iteration 100, training loss = 2.2536\n",
      "Val Loss: 2.2187653106191885\n",
      "Got 788 / 4600 correct (17.130434782608695%)\n",
      "\n",
      "Iteration 200, training loss = 2.2186\n",
      "Val Loss: 2.226397965265357\n",
      "Got 683 / 4600 correct (14.847826086956523%)\n",
      "\n",
      "Iteration 300, training loss = 2.2149\n",
      "Val Loss: 2.2236780498338784\n",
      "Got 845 / 4600 correct (18.369565217391305%)\n",
      "\n",
      "Iteration 400, training loss = 2.2586\n",
      "Val Loss: 2.263830366341964\n",
      "Got 638 / 4600 correct (13.869565217391305%)\n",
      "\n",
      "Iteration 500, training loss = 2.2213\n",
      "Val Loss: 2.207104423771734\n",
      "Got 879 / 4600 correct (19.108695652173914%)\n",
      "\n",
      "Iteration 600, training loss = 2.2720\n",
      "Val Loss: 2.227567620899366\n",
      "Got 791 / 4600 correct (17.195652173913043%)\n",
      "\n",
      "Iteration 700, training loss = 2.2319\n",
      "Val Loss: 2.205299543297809\n",
      "Got 1103 / 4600 correct (23.97826086956522%)\n",
      "\n",
      "Iteration 800, training loss = 2.2686\n",
      "Val Loss: 2.2502850397773413\n",
      "Got 735 / 4600 correct (15.978260869565217%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 900, training loss = 2.2136\n",
      "Val Loss: 2.232626412225806\n",
      "Got 787 / 4600 correct (17.108695652173914%)\n",
      "\n",
      "Val Loss: 2.2323938349018926\n",
      "Got 801 / 4600 correct (17.41304347826087%)\n",
      "******************************\n",
      "End of epoch 22 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.254361656803723, accuracy: 0.1881828464967729\n",
      "Val loss: 2.2323938349018926, accuracy: 0.1741304347826087\n",
      "******************************\n",
      "----------\n",
      "Epoch 23\n",
      "----------\n",
      "Iteration 0, training loss = 2.2620\n",
      "Val Loss: 2.2320587220399277\n",
      "Got 807 / 4600 correct (17.543478260869566%)\n",
      "\n",
      "Iteration 100, training loss = 2.2573\n",
      "Val Loss: 2.213388100914333\n",
      "Got 806 / 4600 correct (17.52173913043478%)\n",
      "\n",
      "Iteration 200, training loss = 2.3061\n",
      "Val Loss: 2.2246865137763647\n",
      "Got 758 / 4600 correct (16.47826086956522%)\n",
      "\n",
      "Iteration 300, training loss = 2.2108\n",
      "Val Loss: 2.212503573168879\n",
      "Got 812 / 4600 correct (17.652173913043477%)\n",
      "\n",
      "Iteration 400, training loss = 2.2248\n",
      "Val Loss: 2.2089357220608257\n",
      "Got 875 / 4600 correct (19.021739130434785%)\n",
      "\n",
      "Iteration 500, training loss = 2.2315\n",
      "Val Loss: 2.210761018421339\n",
      "Got 858 / 4600 correct (18.65217391304348%)\n",
      "\n",
      "Iteration 600, training loss = 2.2361\n",
      "Val Loss: 2.2099113878996475\n",
      "Got 888 / 4600 correct (19.304347826086957%)\n",
      "\n",
      "Iteration 700, training loss = 2.1902\n",
      "Val Loss: 2.209658016329226\n",
      "Got 868 / 4600 correct (18.869565217391305%)\n",
      "\n",
      "Iteration 800, training loss = 2.2520\n",
      "Val Loss: 2.2153582417446636\n",
      "Got 771 / 4600 correct (16.76086956521739%)\n",
      "\n",
      "Iteration 900, training loss = 2.1879\n",
      "Val Loss: 2.2132815226264624\n",
      "Got 860 / 4600 correct (18.695652173913043%)\n",
      "\n",
      "Val Loss: 2.2123663062634678\n",
      "Got 848 / 4600 correct (18.434782608695652%)\n",
      "******************************\n",
      "End of epoch 23 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.237679846920748, accuracy: 0.1961696276088451\n",
      "Val loss: 2.2123663062634678, accuracy: 0.18434782608695652\n",
      "******************************\n",
      "----------\n",
      "Epoch 24\n",
      "----------\n",
      "Iteration 0, training loss = 2.2196\n",
      "Val Loss: 2.2113312068192856\n",
      "Got 846 / 4600 correct (18.391304347826086%)\n",
      "\n",
      "Iteration 100, training loss = 2.2304\n",
      "Val Loss: 2.2228358776673027\n",
      "Got 736 / 4600 correct (16.0%)\n",
      "\n",
      "Iteration 200, training loss = 2.2287\n",
      "Val Loss: 2.2144631769346153\n",
      "Got 760 / 4600 correct (16.52173913043478%)\n",
      "\n",
      "Iteration 300, training loss = 2.2171\n",
      "Val Loss: 2.208151558171148\n",
      "Got 836 / 4600 correct (18.173913043478258%)\n",
      "\n",
      "Iteration 400, training loss = 2.2352\n",
      "Val Loss: 2.2080103158950806\n",
      "Got 845 / 4600 correct (18.369565217391305%)\n",
      "\n",
      "Iteration 500, training loss = 2.1958\n",
      "Val Loss: 2.2151802881904272\n",
      "Got 779 / 4600 correct (16.934782608695652%)\n",
      "\n",
      "Iteration 600, training loss = 2.1513\n",
      "Val Loss: 2.214826355809751\n",
      "Got 768 / 4600 correct (16.695652173913047%)\n",
      "\n",
      "Iteration 700, training loss = 2.1820\n",
      "Val Loss: 2.209279475004777\n",
      "Got 867 / 4600 correct (18.84782608695652%)\n",
      "\n",
      "Iteration 800, training loss = 2.2708\n",
      "Val Loss: 2.20045266462409\n",
      "Got 975 / 4600 correct (21.195652173913043%)\n",
      "\n",
      "Iteration 900, training loss = 2.2431\n",
      "Val Loss: 2.2053586555563887\n",
      "Got 956 / 4600 correct (20.782608695652176%)\n",
      "\n",
      "Val Loss: 2.2061964325282886\n",
      "Got 958 / 4600 correct (20.82608695652174%)\n",
      "******************************\n",
      "End of epoch 24 summary\n",
      "Total samples: 450870\n",
      "Training loss: 2.236746672392923, accuracy: 0.19702796815046464\n",
      "Val loss: 2.2061964325282886, accuracy: 0.2082608695652174\n",
      "******************************\n",
      "Training complete in 420m 20s\n",
      "Best val accuracy: 0.2167391304347826\n",
      "Test accuracy\n",
      "Val Loss: 2.3222806207100652\n",
      "Got 817 / 4602 correct (17.75315080399826%)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "with open('uncertain.txt', 'r') as f:\n",
    "    file_paths = f.readlines()\n",
    "    for file_path in file_paths:\n",
    "        image = io.imread(file_path.strip())\n",
    "        print(file_path)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        print('-' * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
